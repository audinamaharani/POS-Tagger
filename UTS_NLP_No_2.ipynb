{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UTS NLP No.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import Library"
      ],
      "metadata": {
        "id": "ZRSIgeZCJXVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99BSj3yhJGCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c3a3a9-cf4f-4b67-fade-491621c6e295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk melakukan tagging dengan Penn Treebank Tagset, saya akan menggunakan function dari library nltk. NLTK memiliki function word_tokenize yang berguna untuk melakukan tokenize kata dari kalimat. Saya juga menggunakan modul average_perceptron_tagger dan punkt untuk membantu proses tokenize dan taggin"
      ],
      "metadata": {
        "id": "AJ2YyWJkIGXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pos tagging"
      ],
      "metadata": {
        "id": "Q5Q48jWiMO1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fungsi untuk mendapatkan hasil POS Tag\n",
        "def pos_tagger(sentence):\n",
        "  text = word_tokenize(sentence)\n",
        "  tagged_words = nltk.pos_tag(text)\n",
        "  print(tagged_words)"
      ],
      "metadata": {
        "id": "J60bLFihJfat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Kalimat yang ada akan diubah menjadi token menggunakan function word_tokenize()\n",
        "*   Token-token tersebut kemudian diberikan tag yang sesuai dengan jenis katanya menggunakan function post_tag()"
      ],
      "metadata": {
        "id": "Ar4Xp1HsMRqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Please book me a flight to Indonesia. I am planning to visit Jojo Academy this week.\"\n",
        "pos_tagger(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxdKkzpDK3oN",
        "outputId": "3a1c56dd-f943-4417-cba8-59a08207a5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Please', 'VB'), ('book', 'NN'), ('me', 'PRP'), ('a', 'DT'), ('flight', 'NN'), ('to', 'TO'), ('Indonesia', 'NNP'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('planning', 'VBG'), ('to', 'TO'), ('visit', 'VB'), ('Jojo', 'NNP'), ('Academy', 'NNP'), ('this', 'DT'), ('week', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Social Signal Processing can be considered as blue-sky research in the Artificial Intelligence area.\"\n",
        "pos_tagger(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNFO-RYxyW_W",
        "outputId": "a2adaf63-355f-464b-d2b8-4fc6059b994d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Social', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), ('can', 'MD'), ('be', 'VB'), ('considered', 'VBN'), ('as', 'IN'), ('blue-sky', 'JJ'), ('research', 'NN'), ('in', 'IN'), ('the', 'DT'), ('Artificial', 'NNP'), ('Intelligence', 'NNP'), ('area', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I think therefore I am the first principle of Rene Descartes’s philosophy\"\n",
        "pos_tagger(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3oHPhfhyX3U",
        "outputId": "a540afdb-5da6-4963-99e9-4c24ea1f54d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PRP'), ('think', 'VBP'), ('therefore', 'RB'), ('I', 'PRP'), ('am', 'VBP'), ('the', 'DT'), ('first', 'JJ'), ('principle', 'NN'), ('of', 'IN'), ('Rene', 'NNP'), ('Descartes', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('philosophy', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jika dievaluasi, terdapat perbedaan hasil antara model dengan jawaban manual saya. Pada poin a, kata 'book' saya interpretasikan sebagai VB dimana book yang dimaksud di sini adalah memesan. Tetapi menurut model ini, kata 'book' pada kalimat tersebut merupakan NN.\n",
        "\n",
        "Hal ini menunjukkan bahwa tidak semua model dapat menginterpretasikan arti kata sesuai dengan konteks. Tetapi dari 3 kalimat yang ada, jumlah interpretasi yang berbeda sangat kecil dibandingkan dengan jumlah interpretasi yang tepat. Maka dari itu, komputer tidak sel"
      ],
      "metadata": {
        "id": "s2ESgvOVWqsI"
      }
    }
  ]
}